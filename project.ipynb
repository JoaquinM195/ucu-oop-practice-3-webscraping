{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCU - Proyecto Webscraping\n",
    "Proyecto para la Licenciatura en Datos y Negocios de la Universidad Católica del Uruguay"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Scraping de propiedades — Inmobiliaria Uruguay\n",
    "Este notebook descarga listados **públicos** desde *inmobiliariauruguay.com* usando `requests`\n",
    "y analiza el HTML con `BeautifulSoup` para extraer:\n",
    "\n",
    "- Ciudad (agrupado por **Departamento** en el sitio, p. ej. *Montevideo*, *Maldonado*, *Canelones*)\n",
    "- Precio (USD)\n",
    "- Tamaño (m², si está disponible)\n",
    "- Dormitorios (si está disponible)\n",
    "- Link al aviso\n",
    "\n",
    "Requisitos:\n",
    "- `requests`, `beautifulsoup4` (instalar con `pip install requests beautifulsoup4`)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1) Imports y funciones auxiliares"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T02:00:13.425584Z",
     "start_time": "2025-09-19T02:00:13.417674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"es-ES,es;q=0.9\"\n",
    "}\n",
    "\n",
    "BASE = \"https://inmobiliariauruguay.com\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "def get_soup(url):\n",
    "    resp = session.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "def to_int(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    nums = re.findall(r\"[0-9][0-9\\.]*\", text.replace(\"\\xa0\",\" \"))\n",
    "    if not nums:\n",
    "        return None\n",
    "    n = nums[0].replace(\".\", \"\")\n",
    "    try:\n",
    "        return int(n)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def clean_m2(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    x = x.replace(\"m2\", \"\").replace(\"m²\", \"\")\n",
    "    return to_int(x)\n",
    "\n",
    "def parse_title_city(title):\n",
    "    if not title:\n",
    "        return None\n",
    "    import re\n",
    "    parts = re.split(r\"[,–-]\", title)\n",
    "    last = parts[-1].strip() if parts else None\n",
    "    if last:\n",
    "        last = re.sub(r\"\\.$\", \"\", last)\n",
    "    return last or None"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Listado y paginación"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T02:00:16.077963Z",
     "start_time": "2025-09-19T02:00:16.072247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_cards_from_listing(list_url, max_pages=5):\n",
    "    out = []\n",
    "    page = 1\n",
    "    url = list_url\n",
    "    while page <= max_pages and url:\n",
    "        soup = get_soup(url)\n",
    "        for card in soup.select(\"h2 a, h3 a\"):\n",
    "            href = card.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "            title = card.get_text(strip=True)\n",
    "            price_el = None\n",
    "            candidate = card\n",
    "            for _ in range(5):\n",
    "                candidate = candidate.find_parent()\n",
    "                if not candidate: break\n",
    "                price_el = candidate.find(string=lambda s: isinstance(s, str) and \"USD\" in s)\n",
    "                if price_el: break\n",
    "            price_text = (price_el.strip() if isinstance(price_el, str) else price_el.get_text(strip=True)) if price_el else None\n",
    "            out.append({\n",
    "                \"title\": title,\n",
    "                \"price_text\": price_text,\n",
    "                \"detail_url\": urljoin(BASE, href)\n",
    "            })\n",
    "        next_link = None\n",
    "        for a in soup.select(\"a\"):\n",
    "            if a.get_text(strip=True) == str(page+1):\n",
    "                next_link = urljoin(BASE, a.get(\"href\"))\n",
    "        if next_link and next_link != url:\n",
    "            url = next_link\n",
    "            page += 1\n",
    "        else:\n",
    "            break\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Parser de la página de detalle"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T02:00:41.557404Z",
     "start_time": "2025-09-19T02:00:41.550151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_detail(detail_url):\n",
    "    soup = get_soup(detail_url)\n",
    "    title_el = soup.find([\"h1\",\"h2\"])\n",
    "    title = title_el.get_text(strip=True) if title_el else None\n",
    "\n",
    "    price = None\n",
    "    size_m2 = None\n",
    "    bedrooms = None\n",
    "    city = None\n",
    "\n",
    "    detalles = {}\n",
    "    for li in soup.select(\"li\"):\n",
    "        txt = li.get_text(\" \", strip=True)\n",
    "        if \":\" in txt:\n",
    "            k, v = [t.strip() for t in txt.split(\":\", 1)]\n",
    "            detalles[k.lower()] = v\n",
    "\n",
    "    for key in [\"precio\"]:\n",
    "        if key in detalles:\n",
    "            price = to_int(detalles[key])\n",
    "\n",
    "    for key in [\"tamaño de inmueble\", \"tamaño del inmueble\", \"superficie\", \"area de terreno\", \"área de terreno\", \"total edificado\", \"dificada\"]:\n",
    "        if key in detalles and size_m2 is None:\n",
    "            size_m2 = clean_m2(detalles[key])\n",
    "\n",
    "    for key in [\"dormitorios\", \"dormitorio\", \"habitaciones\"]:\n",
    "        if key in detalles and bedrooms is None:\n",
    "            bedrooms = to_int(detalles[key])\n",
    "\n",
    "    if \"departamento\" in detalles:\n",
    "        city = detalles[\"departamento\"].split(\",\")[0].strip()\n",
    "    if not city and title:\n",
    "        city = parse_title_city(title)\n",
    "\n",
    "    if price is None:\n",
    "        import re\n",
    "        usd_text = soup.find(string=re.compile(r\"USD\\s*[0-9\\.,]+\"))\n",
    "        if usd_text:\n",
    "            price = to_int(str(usd_text))\n",
    "\n",
    "    return {\n",
    "        \"ciudad\": city,\n",
    "        \"precio\": price,\n",
    "        \"tamano\": size_m2,\n",
    "        \"habitaciones\": bedrooms,\n",
    "        \"link\": detail_url\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) Ejecución principal y guardado a `propiedades.json`"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-19T02:00:44.216880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_por_ciudades(objetivos, min_props=10, max_pages=5, delay=1.0):\n",
    "    data = {\"ciudades\": []}\n",
    "    import time\n",
    "    for nombre, list_url in objetivos.items():\n",
    "        print(f\"Recolectando en {nombre} ...\")\n",
    "        cards = extract_cards_from_listing(list_url, max_pages=max_pages)\n",
    "        print(f\"  {len(cards)} tarjetas encontradas\")\n",
    "        props = []\n",
    "        seen = set()\n",
    "        for card in cards:\n",
    "            if len(props) >= min_props:\n",
    "                break\n",
    "            detail = card[\"detail_url\"]\n",
    "            if detail in seen:\n",
    "                continue\n",
    "            seen.add(detail)\n",
    "            try:\n",
    "                info = parse_detail(detail)\n",
    "                if not info.get(\"ciudad\"):\n",
    "                    info[\"ciudad\"] = nombre\n",
    "                props.append({\n",
    "                    \"precio\": info.get(\"precio\"),\n",
    "                    \"tamano\": info.get(\"tamano\"),\n",
    "                    \"habitaciones\": info.get(\"habitaciones\"),\n",
    "                    \"link\": info.get(\"link\")\n",
    "                })\n",
    "                print(f\"    OK: {detail}\")\n",
    "                time.sleep(delay)\n",
    "            except Exception as e:\n",
    "                print(f\"    Error {detail}: {e}\")\n",
    "        data[\"ciudades\"].append({\n",
    "            \"nombre\": nombre,\n",
    "            \"propiedades\": props[:min_props]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "OBJETIVOS = {\n",
    "    \"Montevideo\": \"https://inmobiliariauruguay.com/search-results/?type%5B%5D=urbana&states%5B%5D=montevideo\",\n",
    "    \"Maldonado\": \"https://inmobiliariauruguay.com/state/maldonado/\",\n",
    "    \"Canelones\": \"https://inmobiliariauruguay.com/state/canelones/\",\n",
    "}\n",
    "\n",
    "data = scrape_por_ciudades(OBJETIVOS, min_props=10, max_pages=5, delay=0.5)\n",
    "\n",
    "with open(\"propiedades.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    import json\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivo generado: propiedades.json\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recolectando en Montevideo ...\n",
      "  22 tarjetas encontradas\n",
      "    OK: https://inmobiliariauruguay.com/property/apartamento-de-2-dormitorios-en-buceo-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/casa-2-dormitorios-fondo-entrada-auto-con-porton-en-la-union-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/2-casa-en-venta-en-punta-de-manga-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/2-casas-en-un-mismo-padron-en-puntas-de-manga-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/galpon-a-la-venta-en-montevideo-2/\n",
      "    OK: https://inmobiliariauruguay.com/property/galpon-a-la-venta-en-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/apartamento-en-montevideo-9/\n",
      "    OK: https://inmobiliariauruguay.com/property/apartamento-en-montevideo-8/\n",
      "    OK: https://inmobiliariauruguay.com/property/hermoso-apartamento-en-montevideo/\n",
      "    OK: https://inmobiliariauruguay.com/property/apartamento-en-montevideo-6/\n",
      "Recolectando en Maldonado ...\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
